name: Validate Distribution

on:
  workflow_dispatch:
  schedule:
    # Run weekly to catch dependency issues
    - cron: '0 0 * * 0'

jobs:
  validate-build:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Build package
      run: python -m build
    
    - name: Validate package
      run: twine check dist/*
    
    - name: Test wheel installation
      run: |
        python -m venv test-env
        source test-env/bin/activate || test-env\Scripts\activate
        pip install dist/*.whl
        databricks-mcp-server --help
        python -c "import databricks_mcp_server; print('Import successful')"
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      with:
        name: dist-${{ github.sha }}
        path: dist/
        retention-days: 1

  validate-uvx:
    needs: validate-build
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    
    steps:
    - name: Install uv
      uses: astral-sh/setup-uv@v2
      with:
        version: "latest"
    
    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: dist-${{ github.sha }}
        path: dist/
    
    - name: Test uvx installation
      run: |
        uvx --from dist/*.whl databricks-mcp-server --help

  validate-dependencies:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install pip-audit
      run: pip install pip-audit
    
    - name: Build package
      run: |
        pip install build
        python -m build
    
    - name: Extract dependencies
      run: |
        python -c "
        import tomllib
        with open('pyproject.toml', 'rb') as f:
            data = tomllib.load(f)
        deps = data['project']['dependencies']
        with open('requirements.txt', 'w') as f:
            for dep in deps:
                f.write(dep + '\n')
        "
    
    - name: Audit dependencies
      run: pip-audit --requirement requirements.txt --format json --output audit-report.json
    
    - name: Upload audit report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-audit-report
        path: audit-report.json

  validate-metadata:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Install validation tools
      run: |
        pip install build twine check-manifest pyroma
    
    - name: Build package
      run: python -m build
    
    - name: Check manifest
      run: check-manifest
    
    - name: Rate package quality
      run: pyroma .
    
    - name: Validate metadata
      run: twine check dist/*
    
    - name: Check wheel contents
      run: |
        python -c "
        import zipfile
        import sys
        from pathlib import Path
        
        wheel_files = list(Path('dist').glob('*.whl'))
        if not wheel_files:
            sys.exit('No wheel file found')
        
        wheel_file = wheel_files[0]
        with zipfile.ZipFile(wheel_file) as zf:
            files = zf.namelist()
            print('Wheel contents:')
            for file in sorted(files):
                print(f'  {file}')
            
            # Check required files
            required_files = [
                'databricks_mcp_server/__init__.py',
                'databricks_mcp_server/main.py',
                'databricks_mcp_server/server.py',
            ]
            
            for req_file in required_files:
                if not any(req_file in f for f in files):
                    sys.exit(f'Required file missing: {req_file}')
            
            print('All required files present')
        "

  generate-report:
    needs: [validate-build, validate-uvx, validate-dependencies, validate-metadata]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"
    
    - name: Download all artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate validation report
      run: |
        python -c "
        import json
        import os
        from datetime import datetime
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'workflow_run': '${{ github.run_id }}',
            'commit': '${{ github.sha }}',
            'validation_results': {
                'build': '${{ needs.validate-build.result }}',
                'uvx': '${{ needs.validate-uvx.result }}',
                'dependencies': '${{ needs.validate-dependencies.result }}',
                'metadata': '${{ needs.validate-metadata.result }}'
            }
        }
        
        # Add security audit if available
        if os.path.exists('security-audit-report/audit-report.json'):
            with open('security-audit-report/audit-report.json') as f:
                report['security_audit'] = json.load(f)
        
        with open('validation-report.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        print('Validation Report:')
        print(json.dumps(report, indent=2))
        "
    
    - name: Upload validation report
      uses: actions/upload-artifact@v3
      with:
        name: validation-report
        path: validation-report.json